{
 "metadata": {
  "name": "",
  "signature": "sha256:8a405a85a55a9425e317e488e154b74f7e0e42ac9e401dbbee249ebee229e1fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Bayesian Changepoint Detection in Python\n",
      "\n",
      "This code computes the probability of changepoints in a time series.7 In this notebook I show how you can use it.\n",
      "\n",
      "First let's generate some data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from __future__ import division\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_normal_time_series(num, minl=50, maxl=1000):\n",
      "    data = np.array([], dtype=np.float64)\n",
      "    partition = np.random.randint(minl, maxl, num)\n",
      "    for p in partition:\n",
      "        mean = np.random.randn()*10\n",
      "        var = np.random.randn()*1\n",
      "        if var < 0:\n",
      "            var = var * -1\n",
      "        tdata = np.random.normal(mean, var, p)\n",
      "        data = np.concatenate((data, tdata))\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = generate_normal_time_series(7, 10, 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's have a look, how they look like:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=[16, 12])\n",
      "ax.plot(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Offline Changepoint Detection\n",
      "\n",
      "Lets compute the probability of changepoints at each time step. We need two things for that. First a prior of how probable is it to have two successive changepoints with the distance `t`. The second thing is a model of the likelihood of data in a sequence `[s, t]` of the data, given that in this sequence there is *no* changepoint.\n",
      "\n",
      "For this example we assume a uniform prior over the length of sequences (`const_prior`) and a piecewise gaussian model (`gaussian_obs_log_likelihood`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import offline_changepoint_detection as offcd\n",
      "from functools import partial\n",
      "\n",
      "Q, P, Pcp = offcd.offline_changepoint_detection(data, partial(offcd.const_prior, l=(len(data)+1)), offcd.gaussian_obs_log_likelihood)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `offline_changepoint_detection()` function returns three things `Q[t]`, the log-likelihood of data `[t, n]`, `P[t, s]`, the log-likelihood of a datasequence `[t, s]`, given there is no changepoint between `t` and `s` and `Pcp[i, t]`, the log-likelihood that the `i`-th changepoint is at time step `t`. To actually get the probility of a changepoint at time step `t` sum the probabilities.\n",
      "\n",
      "How does that look like for our toy-data?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=[18, 16])\n",
      "ax = fig.add_subplot(2, 1, 1)\n",
      "ax.plot(data[:])\n",
      "ax = fig.add_subplot(2, 1, 2, sharex=ax)\n",
      "ax.plot(np.exp(Pcp).sum(0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That works pretty well, but is somewhat slow. It's possible to speed that up by truncating a sum in the algorithm. However that sometimes leeds to $\\infty$ values. Set the `truncate` parameter to e.g. `-10` to test that out.\n",
      "\n",
      "To understand, what is happening have a look at the following papers:\n",
      "\n",
      "[1] Paul Fearnhead, Exact and Efficient Bayesian Inference for Multiple\n",
      "Changepoint problems, Statistics and computing 16.2 (2006), pp. 203--213\n",
      "\n",
      "[2] Xuan Xiang, Kevin Murphy, Modeling Changing Dependency Structure in\n",
      "Multivariate Time Series, ICML (2007), pp. 1055--1062\n",
      "                                                                                                                                                                                          "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Online Changepoint Detection\n",
      "\n",
      "Let's assume the data points come in one after another and not as these nice batches. During the process you want to know if the new point has the same hyperparameter or different ones. You need an online changepoint detection.\n",
      "\n",
      "Happily there is one, although it's interface is kind of suboptimal so far, in that it expects batches of data still and just assumes they drop in over time... I will change that at some point."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import online_changepoint_detection as oncd\n",
      "\n",
      "R, maxes = oncd.online_changepoint_detection(data, partial(oncd.constant_hazard, 250), oncd.StudentT(10, .03, 1, 0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The online version computes slightly different things. For each time step it returns the probability distribution over the length of the last sequence. E.g. `R[7, 3]` is the probability at time step `7` that the last sequence is already `3` time steps long. It also returns the MAP estimate at each timestep for convenience.\n",
      "\n",
      "To plot the distributions we use a grey-scale colormap, black is zero, white 1. We also plot the probability at each time step for a sequence length of 0, i.e. the probability of the current time step to be a changepoint."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.cm as cm\n",
      "fig, ax = plt.subplots(figsize=[18, 16])\n",
      "ax = fig.add_subplot(3, 1, 1)\n",
      "ax.plot(data)\n",
      "ax = fig.add_subplot(3, 1, 2, sharex=ax)\n",
      "sparsity = 5  # only plot every fifth data for faster display\n",
      "ax.pcolor(np.array(range(0, len(R[:,0]), sparsity)), \n",
      "          np.array(range(0, len(R[:,0]), sparsity)), \n",
      "          -np.log(R[0:-1:sparsity, 0:-1:sparsity]), \n",
      "          cmap=cm.Greys, vmin=0, vmax=1000)\n",
      "ax = fig.add_subplot(3, 1, 3, sharex=ax)\n",
      "ax.plot(R[:, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well, that's much worse but also much faster. To understand the whole algorithm look at\n",
      "\n",
      "[1] Ryan P. Adams, David J.C. MacKay, Bayesian Online Changepoint Detection,\n",
      "arXiv 0710.3742 (2007)\n",
      "\n",
      "There you also find a Matlab version, I based my code on."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}